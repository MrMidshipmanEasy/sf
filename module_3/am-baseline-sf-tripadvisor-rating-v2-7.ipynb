{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Проект №3. О вкусной и здоровой пище \n**[DSPR-60] SF Predict TripAdvisor Rating Matsera Maxim**","metadata":{}},{"cell_type":"markdown","source":"## В этом соревновании нам предстоит предсказать рейтинг ресторана в TripAdvisor\n**По ходу задачи:**\n* Прокачаем работу с pandas\n* Научимся работать с Kaggle Notebooks\n* Поймем как делать предобработку различных данных\n* Научимся работать с пропущенными данными (Nan)\n* Познакомимся с различными видами кодирования признаков\n* Немного попробуем [Feature Engineering](https://ru.wikipedia.org/wiki/Конструирование_признаков) (генерировать новые признаки)\n* И совсем немного затронем ML\n* И многое другое...   ","metadata":{}},{"cell_type":"markdown","source":"# 1. Import","metadata":{}},{"cell_type":"code","source":"# Required packages installation\n!pip install dateparser\n!pip install nltk\n# Download NLTK\n!python -m nltk.downloader all","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:00.407462Z","iopub.execute_input":"2021-11-29T11:10:00.407898Z","iopub.status.idle":"2021-11-29T11:10:17.711889Z","shell.execute_reply.started":"2021-11-29T11:10:00.407857Z","shell.execute_reply":"2021-11-29T11:10:17.710899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport sys\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport json\nimport datetime as dt\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom collections import Counter\nimport itertools\nfrom pathlib import Path\n%matplotlib inline\n\n# Импортируем необходимые библиотеки:\nfrom sklearn.ensemble import RandomForestRegressor # инструмент для создания и обучения модели\nfrom sklearn import metrics # инструменты для оценки точности модели\n# Загружаем специальный инструмент для разбивки:\nfrom sklearn.model_selection import train_test_split\nfrom nltk.sentiment import SentimentIntensityAnalyzer\n\nsia = SentimentIntensityAnalyzer()\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nsys.path.append('/kaggle/input/scrubber4/')\nimport dateparser\nfrom scrubber import TripAdvisorScrubber\n\n# Any results you write to the current directory are saved as output.","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2021-11-29T11:10:17.714423Z","iopub.execute_input":"2021-11-29T11:10:17.714731Z","iopub.status.idle":"2021-11-29T11:10:17.765663Z","shell.execute_reply.started":"2021-11-29T11:10:17.714676Z","shell.execute_reply":"2021-11-29T11:10:17.764709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# зафиксируем версию пакетов, чтобы эксперименты были воспроизводимы:\n!pip freeze > requirements.txt","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:17.76736Z","iopub.execute_input":"2021-11-29T11:10:17.767724Z","iopub.status.idle":"2021-11-29T11:10:20.147412Z","shell.execute_reply.started":"2021-11-29T11:10:17.767657Z","shell.execute_reply":"2021-11-29T11:10:20.146305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Для воспроизводимости результатов зададим:\n# - общий параметр для генерации случайных чисел\nRANDOM_SEED = 42\n# - общую текущую дату\nCURRENT_DATE = pd.to_datetime('25/11/2021')\n","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:20.148983Z","iopub.execute_input":"2021-11-29T11:10:20.149249Z","iopub.status.idle":"2021-11-29T11:10:20.15631Z","shell.execute_reply.started":"2021-11-29T11:10:20.149204Z","shell.execute_reply":"2021-11-29T11:10:20.155318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. DATA","metadata":{}},{"cell_type":"code","source":"DATA_DIR = '/kaggle/input/sf-dst-restaurant-rating/'\ndf_train = pd.read_csv(DATA_DIR+'/main_task.csv')\ndf_test = pd.read_csv(DATA_DIR+'kaggle_task.csv')\nsample_submission = pd.read_csv(DATA_DIR+'/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:20.16011Z","iopub.execute_input":"2021-11-29T11:10:20.160471Z","iopub.status.idle":"2021-11-29T11:10:20.431275Z","shell.execute_reply.started":"2021-11-29T11:10:20.160427Z","shell.execute_reply":"2021-11-29T11:10:20.430445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Датасет, содержащий данные о городах\ndf_city = pd.read_csv(\"/kaggle/input/world-cities/worldcities.csv\")\ndf_city.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:20.435093Z","iopub.execute_input":"2021-11-29T11:10:20.435425Z","iopub.status.idle":"2021-11-29T11:10:20.568412Z","shell.execute_reply.started":"2021-11-29T11:10:20.435376Z","shell.execute_reply":"2021-11-29T11:10:20.567391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Путь к датасету, содержащему слова с позитивной окраской\ndf_pos_words = pd.read_table(\"../input/opinion-lexicon/opinion_lexicon/positive-words.txt\", comment=';', header=None)\n# Путь к датасету, содержащему слова с негативной окраской\ndf_neg_words = pd.read_table(\"../input/opinion-lexicon/opinion_lexicon/negative-words.txt\", comment=';', header=None)\npos_words_list = df_pos_words[0].to_list()\nneg_words_list = df_neg_words[0].to_list()","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:20.571165Z","iopub.execute_input":"2021-11-29T11:10:20.57159Z","iopub.status.idle":"2021-11-29T11:10:20.58933Z","shell.execute_reply.started":"2021-11-29T11:10:20.571395Z","shell.execute_reply":"2021-11-29T11:10:20.588348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visitors_df = pd.read_csv('/kaggle/input/visitors/Visitors.csv')\nd = visitors_df[['City', 'Visitors']].to_dict()\nVisitorsPerCity = dict(zip(d['City'].values(), d['Visitors'].values()))","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:20.590679Z","iopub.execute_input":"2021-11-29T11:10:20.590907Z","iopub.status.idle":"2021-11-29T11:10:20.603085Z","shell.execute_reply.started":"2021-11-29T11:10:20.590873Z","shell.execute_reply":"2021-11-29T11:10:20.602154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. FUNC","metadata":{}},{"cell_type":"code","source":"def test(df):\n    valid_columns = []\n    drop = ['Rating']\n    for c in df.columns:\n        if df[c].dtype not in ['int64', 'float64', 'bool', 'uint8'] and c !='Train':\n            drop.append(c)\n            print(\"DROPPED: \",c, df[c].dtype)\n        else:\n            valid_columns.append(c)\n            \n    print(valid_columns)\n    \n    dft = df[df.Train]\n    pred = dft.drop(drop, axis=1)\n    X = pred\n    y = dft['Rating']\n    \n    # Наборы данных с меткой \"train\" будут использоваться для обучения модели, \"test\" - для тестирования.\n    # Для тестирования мы будем использовать 20% от исходного датасета.\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)\n\n    # Создаём модель (НАСТРОЙКИ НЕ ТРОГАЕМ)\n    regr = RandomForestRegressor(n_estimators=100, verbose=1, n_jobs=-1, random_state=RANDOM_SEED)\n\n    # Обучаем модель на тестовом наборе данных\n    regr.fit(X_train, y_train)\n\n    y_pred = regr.predict(X_test)\n    y_pred_old = y_pred.copy()\n    y_pred = round_of_rating(y_pred) \n    print('MAE с округлением:', metrics.mean_absolute_error(y_test, y_pred), 'MAE без округления:', metrics.mean_absolute_error(y_test, y_pred_old) )\n    \n    plt.rcParams['figure.figsize'] = (10,10)\n    feat_importances = pd.Series(regr.feature_importances_, index=X.columns)\n    feat_importances.nlargest(30).plot(kind='barh')\n","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:20.604113Z","iopub.execute_input":"2021-11-29T11:10:20.604387Z","iopub.status.idle":"2021-11-29T11:10:20.617865Z","shell.execute_reply.started":"2021-11-29T11:10:20.604347Z","shell.execute_reply":"2021-11-29T11:10:20.617161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_season(date):\n   '''\n   Время года из даты\n   '''\n   if (pd.isna(date)):\n       return \"OTHER\"\n   month = date.month\n   if (month > 11 or month <= 3):\n      return \"WINTER\"\n   elif (month == 4 or month == 5):\n      return \"SPRING\"\n   elif (month >=6 and month <= 9):\n      return \"SUMMER\"\n   else:\n      return \"FALL\"","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:20.618865Z","iopub.execute_input":"2021-11-29T11:10:20.619075Z","iopub.status.idle":"2021-11-29T11:10:20.63353Z","shell.execute_reply.started":"2021-11-29T11:10:20.619042Z","shell.execute_reply":"2021-11-29T11:10:20.632644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def is_weekend(date):\n    if (pd.isna(date)):\n        return \"NA\"\n    return \"WORKDAY\" if date.weekday() < 5 else \"WEEKEND\"\n    ","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:20.634858Z","iopub.execute_input":"2021-11-29T11:10:20.635119Z","iopub.status.idle":"2021-11-29T11:10:20.645246Z","shell.execute_reply.started":"2021-11-29T11:10:20.635071Z","shell.execute_reply":"2021-11-29T11:10:20.644557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def round_of_rating(number):\n    \"\"\"\n    Округление рейтинга с точностью до 0.5\n    \"\"\"\n    return np.round(number * 2) / 2","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:20.646167Z","iopub.execute_input":"2021-11-29T11:10:20.646411Z","iopub.status.idle":"2021-11-29T11:10:20.660972Z","shell.execute_reply.started":"2021-11-29T11:10:20.646374Z","shell.execute_reply":"2021-11-29T11:10:20.660092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_Weighed_Rank_RK(row):\n    '''\n    Вычисление относительной позицию ресторана относительно количества ресторанов в городе\n    '''\n    Weighed_Rank = row.Ranking / row['Restaurants_Count']\n    return Weighed_Rank","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:20.66224Z","iopub.execute_input":"2021-11-29T11:10:20.662567Z","iopub.status.idle":"2021-11-29T11:10:20.671821Z","shell.execute_reply.started":"2021-11-29T11:10:20.662529Z","shell.execute_reply":"2021-11-29T11:10:20.671013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_Weighed_Rank(CityMinMax:pd.DataFrame ,row):\n    '''\n    Функция для вычисления относительного положения позиции ресторана в группе по городу\n    '''\n    city_min = CityMinMax[CityMinMax.City == row.City]['min'].iloc[0]\n    city_max = CityMinMax[CityMinMax.City == row.City ]['max'].iloc[0]\n    Weighed_Rank = round(1 - (row.Ranking-city_min) / (city_max-city_min),3)\n    return Weighed_Rank","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:20.673291Z","iopub.execute_input":"2021-11-29T11:10:20.673621Z","iopub.status.idle":"2021-11-29T11:10:20.683591Z","shell.execute_reply.started":"2021-11-29T11:10:20.673557Z","shell.execute_reply":"2021-11-29T11:10:20.682802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cleanup_string(str_in):\n    '''\n    Чистим текст в review для последующй десериализации\n    '''\n    try:      \n        #middle\n        str = str_in.replace(\"', \\\"\",\"⅞\").replace(\"', '\",\"⅞\").replace(\"\\\", '\",\"⅞\").replace(\"\\\", \\\"\",\"⅞\")# \", \n        str = str.replace(\"\\\", \\\"\\\"\",\"⅞\").replace(\"\\\"\\\", '\",\"⅞\").replace(\"\\\", \\'\",\"⅞\").replace(\"\\\"\\\", \\'\",\"⅞\")\n        str = str.replace(\"\\', \\'\",\"⅞\")\n        #left\n        str = str.replace(\"[['\",\"≤\").replace(\"['\",\"⅛\")\n        #right\n        str = str.replace(\"']]\",\"≥\").replace(\"']\",\"⅝\")\n        #cleanups\n        str = str.replace('\\'', ' ').replace('\\\"', ' ').replace('\\'', ' ').replace('\"', ' ')     \n        str = str.replace(\"\\\\\", \" \").replace(\"[[`\", \"≤\").replace('\\'\"', '\\'').replace('\\'\\\"', '\\'')\n        str = str.replace('\"\\'', '\\'').replace('\\\"\\'', '\\'').replace(\"[''\" ,\"≤\").replace(\"[\\'\\'\" ,\"≤\")\n        str = str.replace('\\'', ' ').replace('\\\"', ' ')\n        str = str.replace('\\'', ' ').replace('\\\"', ' ')\n        str = str.replace('\\'', ' ').replace('\"', ' ')\n        #middle\n        str = str.replace(\"⅞\", \"', '\")\n        #left\n        str = str.replace(\"≤\", \"[['\").replace(\"⅛\", \"['\").replace('[[ ', '[[ \\'')\n        #right\n        str = str.replace(\"≥\" ,\"']]\").replace(\"⅝\", \"']\").replace(' ]', ' \\']')\n        str = str.replace(', nan]', '\\', \\'nan\\']').replace('[nan, ', '[\\'nan\\', \\'')\n    except Exception:\n        print('<----',str_in,'---->')\n    return str","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:20.685023Z","iopub.execute_input":"2021-11-29T11:10:20.685334Z","iopub.status.idle":"2021-11-29T11:10:20.701368Z","shell.execute_reply.started":"2021-11-29T11:10:20.685294Z","shell.execute_reply":"2021-11-29T11:10:20.70032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_reviews(rev):\n    '''\n    Получаем review в виде:\n    review['reviews_txt'][1] - list of reviews\n    review['reviews_dt'][1] - list of reviews dates\n    '''\n    if  not pd.isna(rev): \n        #Преобразование к формату json для удобного парсинга\n        rev = str(rev).replace(\"'\",'\"')\n        rev = rev.replace('], [', '], \"reviews_dt\": [')\n        rev = '{ \"reviews_txt\":' + rev + '}'\n        rev = rev.replace('[[','[').replace(']]',']')\n        d = json.loads(rev)\n\n        d['reviews_dt'] = [dt.datetime.strptime(date, '%m/%d/%Y').date() if len(date.split('/')[2])==4 \\\n            else dt.datetime.strptime(date, '%m/%d/%y').date() for date in d['reviews_dt']]\n        return d\n    else:\n        return {}","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:20.702841Z","iopub.execute_input":"2021-11-29T11:10:20.703158Z","iopub.status.idle":"2021-11-29T11:10:20.717122Z","shell.execute_reply.started":"2021-11-29T11:10:20.703104Z","shell.execute_reply":"2021-11-29T11:10:20.716254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rev_time_delta(rev):\n    '''\n    Вычисляем время между review в днях\n    '''\n    if (pd.notna(rev)):\n        reviews_dt_list = get_reviews(rev)['reviews_dt']\n        if reviews_dt_list:\n            return (max(reviews_dt_list) - min(reviews_dt_list)).days\n        else:\n            return dt.timedelta(days=3650).days\n    else:\n        return dt.timedelta(days=3650).days","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:20.718708Z","iopub.execute_input":"2021-11-29T11:10:20.719047Z","iopub.status.idle":"2021-11-29T11:10:20.732142Z","shell.execute_reply.started":"2021-11-29T11:10:20.718984Z","shell.execute_reply":"2021-11-29T11:10:20.731428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_cuisines(cuisines):\n    '''\n    Получаем список кухонь в виде:\n    cuisines[0] - list of cusines\n    если был NaN, то возвращается 'Regional Cusine' -как самая популярная в регионе/городе/стране\n    '''\n    if cuisines == 'NaN': return ['Regional Cusine']\n    if  cuisines:\n        cuisines = str(cuisines).replace(\"'\",'\"')\n        return json.loads(cuisines)\n    else:\n        return ['Regional Cusine']","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:20.733949Z","iopub.execute_input":"2021-11-29T11:10:20.734306Z","iopub.status.idle":"2021-11-29T11:10:20.742937Z","shell.execute_reply.started":"2021-11-29T11:10:20.734241Z","shell.execute_reply":"2021-11-29T11:10:20.742293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"allCusines = []\ndef cuisine_styles_count(row):\n    '''\n    Получаем количество кухонь\n    '''\n    global allCusines\n    cusines = get_cuisines(row['Cuisine_Style'])\n    \n    if row['Cuisine_Style'] != 'NaN':    \n        cusines = get_cuisines(row['Cuisine_Style'])\n        allCusines.extend(cusines)\n        cuisines_count =len(cusines)\n    else:\n        cuisines_count = 1\n\n    return cuisines_count","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:20.743914Z","iopub.execute_input":"2021-11-29T11:10:20.744157Z","iopub.status.idle":"2021-11-29T11:10:20.75364Z","shell.execute_reply.started":"2021-11-29T11:10:20.744111Z","shell.execute_reply":"2021-11-29T11:10:20.752652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_city_population_and_country(df:pd.DataFrame, df_city:pd.DataFrame):\n    '''\n    Получаем популяцию по городам, а так же ISO код страны по городу (из внешних источников)\n    '''\n    population_city_dict = {}\n    country_city_dict = {}\n    cities = df['City'].unique()\n\n    for city in cities:\n    \n        vals = (df_city[df_city.city.str.contains(city)].population / 1000000).max()\n        vals = 0.3 if np.isnan(vals) else vals\n    \n        population_city_dict[city] = vals\n        country =  df_city[df_city.city.str.contains(city)][df_city[df_city.city.str.contains(city)].population == df_city[df_city.city.str.contains(city)].population.max()].iso2\n        country = -1 if country.shape[0] < 1 else country.keys()[0]\n        country_city_dict[city] = country\n\n    population_city_dict['Luxembourg'] = 0.613894 \n    population_city_dict['Brussels'] = 2.115468 \n    population_city_dict['Geneva'] = 0.686562 \n    population_city_dict['Oporto'] = 0.214349 \n    population_city_dict['Ljubljana'] = 0.279631\n\n\n\n    country_city_dict['Luxembourg'] = 442 \n    country_city_dict['Brussels'] = 56 \n    country_city_dict['Geneva'] = 756 \n    country_city_dict['Oporto'] = 620 \n    country_city_dict['Ljubljana'] = 705\n    \n    #Эти данные корректнее\n    population_city_dict = {    'London': 8.173900,\n    'Paris': 2.240621,\n    'Madrid': 3.155360,\n    'Barcelona': 1.593075,\n    'Berlin': 3.326002,\n    'Milan': 1.331586,\n    'Rome': 2.870493,\n    'Prague': 1.272690,\n    'Lisbon': .547733,\n    'Vienna': 1.765649,\n    'Amsterdam': .825080,\n    'Brussels': .144784,\n    'Hamburg': 1.718187,\n    'Munich': 1.364920,\n    'Lyon': .496343,\n    'Stockholm': 1.981263,\n    'Budapest': 1.744665,\n    'Warsaw': 1.720398,\n    'Dublin': .506211 ,\n    'Copenhagen': 1.246611,\n    'Athens': 3.168846,\n    'Edinburgh': .476100,\n    'Zurich': .402275,\n    'Oporto': .221800,\n    'Geneva': .196150,\n    'Krakow': .756183,\n    'Oslo': .673469,\n    'Helsinki': .574579,\n    'Bratislava': .413192,\n    'Luxembourg': .576249,\n    'Ljubljana': .277554\n    }\n    return population_city_dict, country_city_dict","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:20.754867Z","iopub.execute_input":"2021-11-29T11:10:20.755089Z","iopub.status.idle":"2021-11-29T11:10:20.775456Z","shell.execute_reply.started":"2021-11-29T11:10:20.75505Z","shell.execute_reply":"2021-11-29T11:10:20.774225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_capital_city_dict(df_in:pd.DataFrame, df_city:pd.DataFrame):\n    '''\n    Возвращаем словарь город == столица или нет\n    '''\n    capital_city_dict = {}\n    cities = df_in['City'].unique()\n\n    df_city['isCapital'] = df_city.capital.apply(lambda x: True if x == \"primary\" else False)\n\n    for city in cities:\n        vals = df_city[df_city.city.str.contains(city)] \\\n            [df_city[df_city.city.str.contains(city)].population == df_city[df_city.city.str.contains(city)].population.max()].isCapital\n        capital_city_dict[city] = vals.values[0] if len(vals) > 0 else False\n    return capital_city_dict","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:20.777421Z","iopub.execute_input":"2021-11-29T11:10:20.777767Z","iopub.status.idle":"2021-11-29T11:10:20.793568Z","shell.execute_reply.started":"2021-11-29T11:10:20.777709Z","shell.execute_reply":"2021-11-29T11:10:20.792337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def is_cuisine_top_N(cs):\n    '''\n    Возвращаем список кухонь, входящих в основной список кухонь,для остальных Other\n    '''\n    c = get_cuisines(cs)\n    c = set(c)\n\n    shared_cousines=()\n    shared_cousines=c.intersection(topNcusines)\n\n    if len(shared_cousines) != len(c):\n        shared_cousines = list(shared_cousines)\n        shared_cousines.extend(['Other'])\n\n    return list(shared_cousines)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:20.796681Z","iopub.execute_input":"2021-11-29T11:10:20.797199Z","iopub.status.idle":"2021-11-29T11:10:20.808251Z","shell.execute_reply.started":"2021-11-29T11:10:20.796973Z","shell.execute_reply":"2021-11-29T11:10:20.807583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def createWordList(line):\n    wordList2 =[]\n    wordList1 = line.split()\n    for word in wordList1:\n        cleanWord = \"\"\n        for char in word:\n            if char in '!,.?\":;0123456789':\n                char = \"\"\n            cleanWord += char\n        wordList2.append(cleanWord.lower())\n    return wordList2","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:20.809404Z","iopub.execute_input":"2021-11-29T11:10:20.809931Z","iopub.status.idle":"2021-11-29T11:10:20.821015Z","shell.execute_reply.started":"2021-11-29T11:10:20.809699Z","shell.execute_reply":"2021-11-29T11:10:20.820112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def count_positive_words_proportion(reviews):\n    '''\n    Количество позитивных слов в приведенных отзывах\n    '''\n    pos_words_count = 0\n    txts=get_reviews(reviews)['reviews_txt']\n    txt = ' '.join(txts)\n    #print(type(txt))\n    words = createWordList(txt)\n    \n    words_count = len(words) if len(words) > 0 else 1\n    words_count = 1\n    for word in words:\n        if word in pos_words_list:\n            #print(word)\n            pos_words_count +=1  \n    return np.round(pos_words_count / words_count,2)\n\ndef count_negative_words_proportion(reviews):\n    '''\n    Количество негативных слов в приведенных отзывах\n    '''\n    neg_words_count = 0\n    txts=get_reviews(reviews)['reviews_txt']\n    txt = ' '.join(txts)\n    #print(type(txt))\n    words = createWordList(txt)\n    \n    words_count = len(words) if len(words) > 0 else 1\n    words_count = 1\n    for word in words:\n        if word in neg_words_list:\n            #print(word)\n            neg_words_count +=1  \n    return np.round(neg_words_count / words_count,2)\n\ndef list_positive_words(reviews): \n    '''\n    Список уникальных позитивных слов в приведенных отзывах\n    '''\n    txts = get_reviews(reviews)['reviews_txt']\n    txt = ' '.join(txts)\n    words = createWordList(txt)\n    \n    words_count = len(words) if len(words) > 0 else 1\n    words_count = 1\n    pos_words_in_review=set(words).intersection(pos_words_list)\n    if (len(pos_words_in_review) == 0):\n        return np.NAN\n    else:\n        return list(pos_words_in_review)\n\ndef list_negative_words(reviews): \n    '''\n    Список уникальных негативных слов в приведенных отзывах\n    '''\n    txts = get_reviews(reviews)['reviews_txt']\n    txt = ' '.join(txts)\n    words = createWordList(txt)\n    \n    words_count = len(words) if len(words) > 0 else 1\n    words_count = 1\n    neg_words_in_review=set(words).intersection(neg_words_list)\n    if (len(neg_words_in_review) == 0):\n        return np.NAN\n    else:\n        return list(neg_words_in_review)\n    \n\n    ","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:20.823777Z","iopub.execute_input":"2021-11-29T11:10:20.824311Z","iopub.status.idle":"2021-11-29T11:10:20.84598Z","shell.execute_reply.started":"2021-11-29T11:10:20.824256Z","shell.execute_reply":"2021-11-29T11:10:20.845315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def review_sentiment(reviews):\n    \"\"\"\n    Return means sentiment of the reviews\n    \"\"\"\n    reviews = get_reviews(reviews)['reviews_txt']\n    l = len(reviews)\n    if l == 0:\n        return 0\n    \n    accum = 0\n    for review in reviews:\n        accum+= sia.polarity_scores(review)['compound']\n    return accum/l","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:20.847099Z","iopub.execute_input":"2021-11-29T11:10:20.847629Z","iopub.status.idle":"2021-11-29T11:10:20.862488Z","shell.execute_reply.started":"2021-11-29T11:10:20.847569Z","shell.execute_reply":"2021-11-29T11:10:20.861336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scrubber import TripAdvisorScrubber\n\ndef fillTA(row):\n    info = TripAdvisorScrubber(row.URL_TA).build_info()\n    if not info.exist:\n        print(row.URL_TA)\n        missing.append(row.URL_TA)\n        return row\n\n    if pd.isna(row.Number_of_Reviews) and info.reviews_count:\n        row.Number_of_Reviews = info.reviews_count\n        row.Modified = True\n    if row.Reviews == '[[], []]' and info.last_reviews:\n        row.Reviews = info.last_reviews\n        row.Modified = True\n    if pd.isna(row.Cuisine_Style) and info.cuisines:\n        row.Cuisine_Style = info.cuisines\n    if pd.isna(row.Price_Range) and info.price:\n        # print(row, info.price)\n        row.Price_Range = info.price\n    return  row","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:20.863832Z","iopub.execute_input":"2021-11-29T11:10:20.864121Z","iopub.status.idle":"2021-11-29T11:10:20.878655Z","shell.execute_reply.started":"2021-11-29T11:10:20.864061Z","shell.execute_reply":"2021-11-29T11:10:20.875004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Data Info","metadata":{}},{"cell_type":"code","source":"df_train.info()","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:20.880458Z","iopub.execute_input":"2021-11-29T11:10:20.880876Z","iopub.status.idle":"2021-11-29T11:10:20.926456Z","shell.execute_reply.started":"2021-11-29T11:10:20.880828Z","shell.execute_reply":"2021-11-29T11:10:20.925662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:20.927514Z","iopub.execute_input":"2021-11-29T11:10:20.927893Z","iopub.status.idle":"2021-11-29T11:10:20.945897Z","shell.execute_reply.started":"2021-11-29T11:10:20.927854Z","shell.execute_reply":"2021-11-29T11:10:20.945283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ВАЖНО! дря корректной обработки признаков объединяем трейн и тест в один датасет\n\ndf_train['Train'] = True # помечаем где у нас трейн\ndf_test['Train'] = False # помечаем где у нас тест\ndf_test['Rating'] = 0 # в тесте у нас нет значения Rating, мы его должны предсказать, по этому пока просто заполняем нулями\n\ndata = df_test.append(df_train, sort=False).reset_index(drop=True) # объединяем","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:20.94708Z","iopub.execute_input":"2021-11-29T11:10:20.947452Z","iopub.status.idle":"2021-11-29T11:10:21.0035Z","shell.execute_reply.started":"2021-11-29T11:10:20.947415Z","shell.execute_reply":"2021-11-29T11:10:21.002762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.columns = list(map(lambda x: x.replace(\" \",\"_\"), data.columns))\ndata.info()","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:21.004567Z","iopub.execute_input":"2021-11-29T11:10:21.004911Z","iopub.status.idle":"2021-11-29T11:10:21.050963Z","shell.execute_reply.started":"2021-11-29T11:10:21.004874Z","shell.execute_reply":"2021-11-29T11:10:21.050034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#updated from website\nta_updated = Path(\"/kaggle/input/tripadvisorupdated2/ta_updated2.csv\")\nif not ta_updated.is_file():\n    # missing data\n    mdf = data[(data.Reviews.eq('[[], []]')) | (data.Cuisine_Style.isna()) | (data.Price_Range.isna()) | (data.Number_of_Reviews.isna())]\n    res = mdf.apply(fillTA, axis=1)\n    data.update(res)\n    data.to_csv(ta_update)\n    \ndata = pd.read_csv(ta_updated)\ndata = data.drop(['Unnamed:_0','Unnamed: 0'], axis=1)\n\ndf_train = data[data.Train==True]\ndf_train.info()\ndf_test = data[data.Train==False]\ndf_test.info()","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:24:05.128083Z","iopub.execute_input":"2021-11-29T11:24:05.128714Z","iopub.status.idle":"2021-11-29T11:24:05.484175Z","shell.execute_reply.started":"2021-11-29T11:24:05.128642Z","shell.execute_reply":"2021-11-29T11:24:05.483335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.Train.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:21.385054Z","iopub.execute_input":"2021-11-29T11:10:21.385364Z","iopub.status.idle":"2021-11-29T11:10:21.394954Z","shell.execute_reply.started":"2021-11-29T11:10:21.385312Z","shell.execute_reply":"2021-11-29T11:10:21.394108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Первоначальная версия датасета состоит из десяти столбцов, содержащих следующую информацию:\n\n- **Restaurant_id** — идентификационный номер ресторана / сети ресторанов;\n- **City** — город, в котором находится ресторан;\n- **Cuisine Style** — кухня или кухни, к которым можно отнести блюда, предлагаемые в ресторане;\n- **Ranking** — место, которое занимает данный ресторан среди всех ресторанов своего города;\n- **Rating** — рейтинг ресторана по данным TripAdvisor (именно это значение должна будет предсказывать модель);\n- **Price Range** — диапазон цен в ресторане;\n- **Number of Reviews** — количество отзывов о ресторане;\n- **Reviews** — данные о двух отзывах, которые отображаются на сайте ресторана;\n- **URL_TA** — URL страницы ресторана на TripAdvisor;\n- **ID_TA** — идентификатор ресторана в базе данных TripAdvisor.","metadata":{}},{"cell_type":"code","source":"# Выбираем нужные для последующего анализа столбцы\ndf = data.drop('URL_TA',axis=1).copy()","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:21.396633Z","iopub.execute_input":"2021-11-29T11:10:21.396909Z","iopub.status.idle":"2021-11-29T11:10:21.415542Z","shell.execute_reply.started":"2021-11-29T11:10:21.39686Z","shell.execute_reply":"2021-11-29T11:10:21.414686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Как видим, большинство признаков у нас требует очистки и предварительной обработки.","metadata":{}},{"cell_type":"markdown","source":"# 5. Обработка NAN и Обработка признаков","metadata":{}},{"cell_type":"markdown","source":"**Посмотрим на признаки и к-во пропусков (NaN)**","metadata":{}},{"cell_type":"code","source":"df.info()\nprint(\"\\nКоличество пропусков:\")\nfor col in df.columns:\n    if data[col].isna().sum() > 0:\n        print(col, \"\\t:\", data[col].isna().sum())","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:21.416994Z","iopub.execute_input":"2021-11-29T11:10:21.417253Z","iopub.status.idle":"2021-11-29T11:10:21.512331Z","shell.execute_reply.started":"2021-11-29T11:10:21.41721Z","shell.execute_reply":"2021-11-29T11:10:21.511396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Посмотрим на признаки и к-во уникальных значений**","metadata":{}},{"cell_type":"code","source":"df.nunique(dropna=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:21.513611Z","iopub.execute_input":"2021-11-29T11:10:21.514009Z","iopub.status.idle":"2021-11-29T11:10:21.617434Z","shell.execute_reply.started":"2021-11-29T11:10:21.513963Z","shell.execute_reply":"2021-11-29T11:10:21.616295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Посмотрим на гистограммы числовых признаков**","metadata":{}},{"cell_type":"code","source":"df['Train']","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:21.618982Z","iopub.execute_input":"2021-11-29T11:10:21.6194Z","iopub.status.idle":"2021-11-29T11:10:21.62721Z","shell.execute_reply.started":"2021-11-29T11:10:21.619337Z","shell.execute_reply":"2021-11-29T11:10:21.626248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[df.Train][['Ranking', 'Rating', 'Number_of_Reviews']].hist(figsize=(20, 10), bins=100);\nplt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:21.628879Z","iopub.execute_input":"2021-11-29T11:10:21.629246Z","iopub.status.idle":"2021-11-29T11:10:23.563957Z","shell.execute_reply.started":"2021-11-29T11:10:21.629161Z","shell.execute_reply":"2021-11-29T11:10:23.563048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[df.Train]['Restaurant_id'].apply(lambda x: x.split('_')[1]).astype(int).hist(figsize=(10,5), bins=100)\nplt.tight_layout()\n# Restaurant_id Очень похож на Ranking","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:23.565569Z","iopub.execute_input":"2021-11-29T11:10:23.565902Z","iopub.status.idle":"2021-11-29T11:10:24.269803Z","shell.execute_reply.started":"2021-11-29T11:10:23.565838Z","shell.execute_reply":"2021-11-29T11:10:24.268731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[df.Train]['ID_TA'].apply(lambda x: x.replace('d','')).astype(int).hist(figsize=(10, 5), bins=100)\nplt.tight_layout()\n# Видно Несколько групп - на ID - точно не похоже. ","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:24.271819Z","iopub.execute_input":"2021-11-29T11:10:24.272544Z","iopub.status.idle":"2021-11-29T11:10:24.816341Z","shell.execute_reply.started":"2021-11-29T11:10:24.272465Z","shell.execute_reply":"2021-11-29T11:10:24.815256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['ID_TA'] = df['ID_TA'].apply(lambda x: x[1:]).astype(int)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:24.817771Z","iopub.execute_input":"2021-11-29T11:10:24.818219Z","iopub.status.idle":"2021-11-29T11:10:24.883172Z","shell.execute_reply.started":"2021-11-29T11:10:24.818157Z","shell.execute_reply":"2021-11-29T11:10:24.882054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reviews - убираем NaN и \"причесываем\" текст отзывов \ndf['Reviews_txt_NaN'] = df['Reviews'].apply(lambda x: x ==  '[[], []]')\n\ndf['Reviews'] = df['Reviews'].fillna('[[], []]')\ndf['Reviews'] = df['Reviews'].apply(lambda x: cleanup_string(x))","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:24.885073Z","iopub.execute_input":"2021-11-29T11:10:24.885567Z","iopub.status.idle":"2021-11-29T11:10:25.583685Z","shell.execute_reply.started":"2021-11-29T11:10:24.885526Z","shell.execute_reply":"2021-11-29T11:10:25.582841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Перекодируем Price Range и удаляем NaN\ncleanup_nums = {'Price_Range': {\"$\": 1, \"$$ - $$$\": 2, \"$$$$\": 3, np.NaN: 2}}\n# чаще всего встречается \"$$ - $$$\", поэтому пропуски заменили на 2\ndf['Price_Range_NaN'] = df['Price_Range'].isna()\ndf.replace(cleanup_nums, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:25.584938Z","iopub.execute_input":"2021-11-29T11:10:25.585369Z","iopub.status.idle":"2021-11-29T11:10:25.634483Z","shell.execute_reply.started":"2021-11-29T11:10:25.58532Z","shell.execute_reply":"2021-11-29T11:10:25.633613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Получаем Cuisines Count, самую популярную кухню, среднее к-во кухонь в ресторане и устраняем NaN\ndf['Cuisine_Style_NAN'] = df['Cuisine_Style'].isna()\ndf['Cuisine_Style'] = df['Cuisine_Style'].fillna('NaN')\ndf['Cuisines_Count'] = df.apply(cuisine_styles_count, axis=1)\n\n## TODO popular in city, does not improve MAE\nmost_popular_cusine = pd.Series(allCusines).value_counts().index[0]\naverage_cousines_count = np.round(df['Cuisines_Count'].mean())","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:25.63627Z","iopub.execute_input":"2021-11-29T11:10:25.636597Z","iopub.status.idle":"2021-11-29T11:10:28.520165Z","shell.execute_reply.started":"2021-11-29T11:10:25.636539Z","shell.execute_reply":"2021-11-29T11:10:28.519401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Number of Reviews\ndf['Number_of_Reviews_NAN'] = df['Number_of_Reviews'].isna()\nreplace_val = df['Number_of_Reviews'].mean()\nreplace_val = np.round(replace_val)\ndf['Number_of_Reviews'] = df['Number_of_Reviews'].fillna(replace_val)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:28.521506Z","iopub.execute_input":"2021-11-29T11:10:28.521959Z","iopub.status.idle":"2021-11-29T11:10:28.530909Z","shell.execute_reply.started":"2021-11-29T11:10:28.521918Z","shell.execute_reply":"2021-11-29T11:10:28.53031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. EDA Анализ данных\nНа этом этапе мы строим графики, ищем закономерности, аномалии, выбросы или связи между признаками.\nВ общем цель этого этапа понять, что эти данные могут нам дать и как признаки могут быть взаимосвязаны между собой.\nПонимание изначальных признаков позволит сгенерировать новые, более сильные и, тем самым, сделать нашу модель лучше.","metadata":{}},{"cell_type":"markdown","source":"## 6.1 Распределение признаков","metadata":{}},{"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (10,5)\ndf[df.Train]['Ranking'].hist(bins=100)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:28.532347Z","iopub.execute_input":"2021-11-29T11:10:28.532834Z","iopub.status.idle":"2021-11-29T11:10:29.180732Z","shell.execute_reply.started":"2021-11-29T11:10:28.532615Z","shell.execute_reply":"2021-11-29T11:10:29.179527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"У нас много ресторанов, которые не дотягивают и до 2500 места в своем городе, а что там по городам?","metadata":{}},{"cell_type":"code","source":"df[df.Train]['City'].value_counts(ascending=True).plot(kind='barh')","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:29.183348Z","iopub.execute_input":"2021-11-29T11:10:29.183864Z","iopub.status.idle":"2021-11-29T11:10:29.536778Z","shell.execute_reply.started":"2021-11-29T11:10:29.183808Z","shell.execute_reply":"2021-11-29T11:10:29.536087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[df.Train]['Ranking'][df[df.Train]['City'] =='London'].hist(bins=100)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:29.53808Z","iopub.execute_input":"2021-11-29T11:10:29.538583Z","iopub.status.idle":"2021-11-29T11:10:29.961113Z","shell.execute_reply.started":"2021-11-29T11:10:29.538526Z","shell.execute_reply":"2021-11-29T11:10:29.960501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# посмотрим на топ 10 городов\nfor x in (df[df.Train]['City'].value_counts())[0:10].index:\n    df[df.Train]['Ranking'][df[df.Train]['City'] == x].hist(bins=100)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:29.962955Z","iopub.execute_input":"2021-11-29T11:10:29.963598Z","iopub.status.idle":"2021-11-29T11:10:32.852357Z","shell.execute_reply.started":"2021-11-29T11:10:29.963533Z","shell.execute_reply":"2021-11-29T11:10:32.851225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Получается, что Ranking имеет нормальное распределение, просто в больших городах больше ресторанов, из-за мы этого имеем смещение.  \nДля устранения смещения нормализуем Ranking, то есть проведём min-max нормализацию признака (Min-Max Scaling)","metadata":{}},{"cell_type":"code","source":"scalers = {}\ndf['RankingScaled']  = 0\ncities = df.City.unique()\nfor city in cities:\n    c = df[df.City==city].Ranking\n    mi = c.min()\n    ma = c.max()\n    scalers[city]= [mi, ma]\n    c2 =  c.apply(lambda x: (x-mi)/(ma-mi)*1000)\n    df[df.City==city]['RankingScaled'] = c2\n    print(f\"{city}\\t{mi},\\t{ma}\\t{c2.min()},\\t{c2.max()}\")\n    \ndef scale(row):\n    mi, ma = scalers[row.City]\n    row.RankingScaled = (row.Ranking-mi)/(ma-mi)*1000\n    return row\ndf = df.apply(scale, axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:32.854079Z","iopub.execute_input":"2021-11-29T11:10:32.854691Z","iopub.status.idle":"2021-11-29T11:10:46.00446Z","shell.execute_reply.started":"2021-11-29T11:10:32.85463Z","shell.execute_reply":"2021-11-29T11:10:46.003579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for x in (df[df.Train]['City'].value_counts())[0:10].index:\n    df[df.Train]['RankingScaled'][df[df.Train]['City'] == x].hist(bins=100)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:46.006063Z","iopub.execute_input":"2021-11-29T11:10:46.006452Z","iopub.status.idle":"2021-11-29T11:10:48.791709Z","shell.execute_reply.started":"2021-11-29T11:10:46.006385Z","shell.execute_reply":"2021-11-29T11:10:48.790575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 6.2 Выбросы для числовых признаков ","metadata":{}},{"cell_type":"code","source":"### 6.3 Number of reviews\nplt.rcParams['figure.figsize'] = (10,5)\nnor = df.Number_of_Reviews\nnor.hist(bins=100)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:48.793524Z","iopub.execute_input":"2021-11-29T11:10:48.793878Z","iopub.status.idle":"2021-11-29T11:10:49.314995Z","shell.execute_reply.started":"2021-11-29T11:10:48.793824Z","shell.execute_reply":"2021-11-29T11:10:49.31387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nor[nor>2000].hist(bins=100)\nsns.boxplot(nor)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:49.317023Z","iopub.execute_input":"2021-11-29T11:10:49.317722Z","iopub.status.idle":"2021-11-29T11:10:49.826011Z","shell.execute_reply.started":"2021-11-29T11:10:49.317653Z","shell.execute_reply":"2021-11-29T11:10:49.824846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def scale_down(value):\n    if value > 2700:\n        value = value/100\n    return value\ndf.Number_of_Reviews = nor.apply(scale_down)\ndf.Number_of_Reviews.hist(bins=100)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:49.828098Z","iopub.execute_input":"2021-11-29T11:10:49.828485Z","iopub.status.idle":"2021-11-29T11:10:50.482422Z","shell.execute_reply.started":"2021-11-29T11:10:49.828424Z","shell.execute_reply":"2021-11-29T11:10:50.48137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6.2 Распределение целевой переменной","metadata":{}},{"cell_type":"code","source":"df[df.Train]['Rating'].value_counts(ascending=True).plot(kind='barh')","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:50.484144Z","iopub.execute_input":"2021-11-29T11:10:50.484498Z","iopub.status.idle":"2021-11-29T11:10:50.683611Z","shell.execute_reply.started":"2021-11-29T11:10:50.484443Z","shell.execute_reply":"2021-11-29T11:10:50.682839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6.3 Посмотрим распределение целевой переменной относительно признака","metadata":{}},{"cell_type":"code","source":"df[df.Train]['Ranking'][df[df.Train]['Rating'] == 5].hist(bins=100)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:50.684999Z","iopub.execute_input":"2021-11-29T11:10:50.685535Z","iopub.status.idle":"2021-11-29T11:10:51.112485Z","shell.execute_reply.started":"2021-11-29T11:10:50.685479Z","shell.execute_reply":"2021-11-29T11:10:51.111527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[df.Train]['Ranking'][df[df.Train]['Rating'] < 4].hist(bins=100)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:51.114014Z","iopub.execute_input":"2021-11-29T11:10:51.114544Z","iopub.status.idle":"2021-11-29T11:10:51.540473Z","shell.execute_reply.started":"2021-11-29T11:10:51.114484Z","shell.execute_reply":"2021-11-29T11:10:51.539765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Рестораны с меньшим рейтингом располагаются на более худших местах в рейтинге по городу, что логично","metadata":{}},{"cell_type":"markdown","source":"## 6.4 Корреляция имеющихся признаков","metadata":{}},{"cell_type":"markdown","source":"Практически единственным признаком, коррелирующим с Rating является Ranking. Он, в свою очередь, уже имеет слабую корреляцию практически со всеми признаками ","metadata":{}},{"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (15,15)\nsns.heatmap(df[df.Train].drop(['Train'], axis=1).corr(), square=True,\n            annot=True, fmt=\".1f\", linewidths=1, cmap=\"cool\")\nplt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:51.544145Z","iopub.execute_input":"2021-11-29T11:10:51.544477Z","iopub.status.idle":"2021-11-29T11:10:52.673394Z","shell.execute_reply.started":"2021-11-29T11:10:51.544419Z","shell.execute_reply":"2021-11-29T11:10:52.672332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 7. Генерация новых признаков (пока без dummies)\nПодключаем внешние данные","metadata":{}},{"cell_type":"code","source":"population_city_dict = {}\ncountry_city_dict = {}\n# Получаем словари популяции по городам, а так же ISO код страны по городу\npopulation_city_dict, country_city_dict = get_city_population_and_country(df, df_city)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:52.674712Z","iopub.execute_input":"2021-11-29T11:10:52.67502Z","iopub.status.idle":"2021-11-29T11:10:56.320295Z","shell.execute_reply.started":"2021-11-29T11:10:52.674972Z","shell.execute_reply":"2021-11-29T11:10:56.319481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Вычисляем страну для города в каждой строке\ndf['Country'] = df[\"City\"].apply(lambda x: country_city_dict[x])","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:56.321782Z","iopub.execute_input":"2021-11-29T11:10:56.322319Z","iopub.status.idle":"2021-11-29T11:10:56.365597Z","shell.execute_reply.started":"2021-11-29T11:10:56.32226Z","shell.execute_reply":"2021-11-29T11:10:56.364391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Вычисляем к-во ресторанов для города в каждой строке\nrestorants_in_city = df.groupby('City')['Ranking'].count().to_dict()\ndf['Restaurants_Count'] = df['City'].map(restorants_in_city)\nrestorants_in_city","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:56.367539Z","iopub.execute_input":"2021-11-29T11:10:56.367927Z","iopub.status.idle":"2021-11-29T11:10:56.396069Z","shell.execute_reply.started":"2021-11-29T11:10:56.367854Z","shell.execute_reply":"2021-11-29T11:10:56.394936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Вычисляем население (в тыс. чел) для города в каждой строке\ndf['Population'] = df[\"City\"].map(population_city_dict)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:56.397997Z","iopub.execute_input":"2021-11-29T11:10:56.398644Z","iopub.status.idle":"2021-11-29T11:10:56.415662Z","shell.execute_reply.started":"2021-11-29T11:10:56.398498Z","shell.execute_reply":"2021-11-29T11:10:56.41417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Вычисляем к-во ресторанов на 1000 чел для города в каждой строке\ndf['Restaurants_for_Population'] = df.Restaurants_Count / (df['Population']*1000)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:56.41778Z","iopub.execute_input":"2021-11-29T11:10:56.418321Z","iopub.status.idle":"2021-11-29T11:10:56.519785Z","shell.execute_reply.started":"2021-11-29T11:10:56.418226Z","shell.execute_reply":"2021-11-29T11:10:56.518821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Visitors'] = df[\"City\"].map(VisitorsPerCity)\ndf['Restaurants_for_Visitors'] = df.Restaurants_Count / (df['Visitors']*1000)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:56.521386Z","iopub.execute_input":"2021-11-29T11:10:56.52181Z","iopub.status.idle":"2021-11-29T11:10:56.540837Z","shell.execute_reply.started":"2021-11-29T11:10:56.521739Z","shell.execute_reply":"2021-11-29T11:10:56.540072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Вычисляем является ли город столицей в каждой строке\ncapital_city_dict = get_capital_city_dict(df, df_city)\ndf['isCapital'] = df[\"City\"].apply(lambda x: capital_city_dict[x])","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:56.542199Z","iopub.execute_input":"2021-11-29T11:10:56.542754Z","iopub.status.idle":"2021-11-29T11:10:59.266516Z","shell.execute_reply.started":"2021-11-29T11:10:56.542504Z","shell.execute_reply":"2021-11-29T11:10:59.26569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Получаем относительную позицию ресторана среди всех ресторанов города\ndf['Weighed_Rank'] = df.apply(lambda x: get_Weighed_Rank_RK(x), axis=1)\n\nCityMinMax = df.groupby('City')['Ranking'].agg([min,max])\nCityMinMax =CityMinMax.reset_index()\ndf['Weighed_Rank_min_max'] = df.apply(lambda x: get_Weighed_Rank(CityMinMax, x), axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:10:59.267957Z","iopub.execute_input":"2021-11-29T11:10:59.268262Z","iopub.status.idle":"2021-11-29T11:12:33.441451Z","shell.execute_reply.started":"2021-11-29T11:10:59.268178Z","shell.execute_reply":"2021-11-29T11:12:33.440482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Флаги (1/0) isMostPopCusine - есть ли в ресторане самая популярная кухня; isMultyCusine - к-во кухонь в ресторане больше или столько же чем в среднем\ndf['isMostPopCusine'] = df.Cuisine_Style.apply(lambda x: 1 if most_popular_cusine in x else 0 )\ndf['isMultyCusine'] = df.Cuisines_Count.apply(lambda x: 1 if  x >= average_cousines_count else 0 )","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:12:33.442817Z","iopub.execute_input":"2021-11-29T11:12:33.443048Z","iopub.status.idle":"2021-11-29T11:12:33.539023Z","shell.execute_reply.started":"2021-11-29T11:12:33.443013Z","shell.execute_reply":"2021-11-29T11:12:33.538222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# RevTimeDelta - время между review в днях\ndf['RevTimeDelta'] = df.Reviews.apply(rev_time_delta)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:12:33.542301Z","iopub.execute_input":"2021-11-29T11:12:33.542968Z","iopub.status.idle":"2021-11-29T11:12:35.492832Z","shell.execute_reply.started":"2021-11-29T11:12:33.542905Z","shell.execute_reply":"2021-11-29T11:12:35.491931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# NewestReviewDate - время, прошедшее со момента последнего review\ndf['NewestReviewDate'] = df.Reviews.apply(lambda x: get_reviews(x)['reviews_dt'])\ndf['NewestReviewDate'] = df.NewestReviewDate.apply(lambda x: sorted(x,reverse=True)[0] if len(x)!=0 else pd.NaT)\ndf['NewestReviewDate'] = df.NewestReviewDate.fillna(dt.date(1970,1,1))\ndf['NewestReviewDate'] = df.NewestReviewDate.apply(lambda x: (CURRENT_DATE.date()-x).total_seconds()//86400)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:12:35.494509Z","iopub.execute_input":"2021-11-29T11:12:35.494874Z","iopub.status.idle":"2021-11-29T11:12:37.62086Z","shell.execute_reply.started":"2021-11-29T11:12:35.494809Z","shell.execute_reply":"2021-11-29T11:12:37.619984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['NewestReviewSeason'] = df.Reviews.apply(lambda x: get_reviews(x)['reviews_dt'])\ndf['NewestReviewSeason'] = df.NewestReviewSeason.apply(lambda x: sorted(x,reverse=True)[0] if len(x)!=0 else pd.NaT)\n## day of week\ndf['ReviewsWeekend'] = df.NewestReviewSeason.apply(lambda x: is_weekend(x))\ndf['NewestReviewSeason'] = df.NewestReviewSeason.apply(lambda x: get_season(x))","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:12:37.622756Z","iopub.execute_input":"2021-11-29T11:12:37.623386Z","iopub.status.idle":"2021-11-29T11:12:40.106162Z","shell.execute_reply.started":"2021-11-29T11:12:37.62325Z","shell.execute_reply":"2021-11-29T11:12:40.105453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#  'TxtReviewsCount' - к-во отзывов, не сильно улучшает результат, но пусть будут\ndf['TxtReviewsCount'] = df.Reviews.apply(lambda x: len(get_reviews(x)['reviews_txt']))","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:12:40.1076Z","iopub.execute_input":"2021-11-29T11:12:40.108208Z","iopub.status.idle":"2021-11-29T11:12:42.028831Z","shell.execute_reply.started":"2021-11-29T11:12:40.108047Z","shell.execute_reply":"2021-11-29T11:12:42.02798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# К-во позитивных слов в представленных отзывах\ndf['PositiveWords'] = df.Reviews.apply(lambda x: count_positive_words_proportion(x))\n# Список уникальных позитивных слов в представленных отзывах\ndf['PositiveWordsList'] = df.Reviews.apply(lambda x: list_positive_words(x))\n\n","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:12:42.030404Z","iopub.execute_input":"2021-11-29T11:12:42.03075Z","iopub.status.idle":"2021-11-29T11:12:59.253153Z","shell.execute_reply.started":"2021-11-29T11:12:42.030691Z","shell.execute_reply":"2021-11-29T11:12:59.252326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['ReviewsSentiment'] = df['Reviews'].apply(review_sentiment)\nmean = df.ReviewsSentiment.median()\ndf['ReviewsSentiment'] = df['ReviewsSentiment'].apply(lambda x: mean if x==0 else x)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:12:59.254747Z","iopub.execute_input":"2021-11-29T11:12:59.255096Z","iopub.status.idle":"2021-11-29T11:13:09.43147Z","shell.execute_reply.started":"2021-11-29T11:12:59.255028Z","shell.execute_reply":"2021-11-29T11:13:09.430431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cusines_in_city={}\ncusines_count_in_city={}\nfor city_name, group in df.groupby('City'):\n    #Получим серию со списками кухонь для групп\n    cusines = group['Cuisine_Style'].apply(get_cuisines)\n    #Получим список кухонь в группе\n    cusines_list = list(itertools.chain.from_iterable(cusines))\n    #Посчитаем и запишем число совпадений для каждой кухни в каждой группе при помощи Counter\n    cusines_in_city[city_name] = Counter(cusines_list)    \n\nfor city_name in cusines_in_city.keys():\n    cusines_count_in_city[city_name] = len(cusines_in_city[city_name])\n  \ndf['Cusines_Count_In_City'] = df.City.map(cusines_count_in_city)\n\n## TODO recalculate","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:13:09.434257Z","iopub.execute_input":"2021-11-29T11:13:09.435278Z","iopub.status.idle":"2021-11-29T11:13:09.80837Z","shell.execute_reply.started":"2021-11-29T11:13:09.435217Z","shell.execute_reply":"2021-11-29T11:13:09.8075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Относительная доля кухонь в ресторане\ndf['Weighed_Cuisines_Count'] = df['Cuisines_Count'] / df['Cusines_Count_In_City']  ","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:13:09.809961Z","iopub.execute_input":"2021-11-29T11:13:09.810263Z","iopub.status.idle":"2021-11-29T11:13:09.816765Z","shell.execute_reply.started":"2021-11-29T11:13:09.810204Z","shell.execute_reply":"2021-11-29T11:13:09.815677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Самая популярная кухня в городе\ndf['Most_Common_Cusine_in_City'] = df['City'].apply(lambda x: cusines_in_city[x].most_common(1)[0][0])\n# Заменим пропуски на самую популярную\n### TODO заменить на 3 самых популярных\ndf['Cuisine_Style'] = df.apply(lambda x: x['Cuisine_Style'] if x['Cuisine_Style_NAN'] ==False else [x['Most_Common_Cusine_in_City']], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:13:09.819477Z","iopub.execute_input":"2021-11-29T11:13:09.819974Z","iopub.status.idle":"2021-11-29T11:13:12.348839Z","shell.execute_reply.started":"2021-11-29T11:13:09.81991Z","shell.execute_reply":"2021-11-29T11:13:12.348114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# зависимость места ресторана в городе от населения\ndf['Weighed_Rank_by_Population'] = df['Weighed_Rank']  / df['Population'] \n# weighted rank by Visitors\ndf['Weighed_Rank_by_Visitors'] = df['Weighed_Rank']  / df['Visitors'] ","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:13:12.35012Z","iopub.execute_input":"2021-11-29T11:13:12.350583Z","iopub.status.idle":"2021-11-29T11:13:12.359176Z","shell.execute_reply.started":"2021-11-29T11:13:12.35054Z","shell.execute_reply":"2021-11-29T11:13:12.35832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['PositiveWords_in_Reviews'] = df['PositiveWords'] / df['Number_of_Reviews']\ndf['Sentiments_in_Reviews'] = df['ReviewsSentiment'] / df['Number_of_Reviews']","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:13:12.360896Z","iopub.execute_input":"2021-11-29T11:13:12.361332Z","iopub.status.idle":"2021-11-29T11:13:12.371919Z","shell.execute_reply.started":"2021-11-29T11:13:12.361237Z","shell.execute_reply":"2021-11-29T11:13:12.371119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Как часто в городе оставляют отзывы\ndf['NRP'] = df['Number_of_Reviews'] / df['Population']\n\ndf['NRV'] = df['Number_of_Reviews'] / df['Visitors']","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:13:12.373213Z","iopub.execute_input":"2021-11-29T11:13:12.373532Z","iopub.status.idle":"2021-11-29T11:13:12.383869Z","shell.execute_reply.started":"2021-11-29T11:13:12.373479Z","shell.execute_reply":"2021-11-29T11:13:12.383061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Ранг ресторана с учетом частоты отзывов в городе\ndf['WRR'] =  df['Weighed_Rank']  *  df['NRP'] \ndf['WRV'] =  df['Weighed_Rank']  *  df['NRV'] \ndf['Relative_Price_Range'] = df['Price_Range'] / df['Weighed_Rank']","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:13:12.385598Z","iopub.execute_input":"2021-11-29T11:13:12.385946Z","iopub.status.idle":"2021-11-29T11:13:12.398382Z","shell.execute_reply.started":"2021-11-29T11:13:12.385905Z","shell.execute_reply":"2021-11-29T11:13:12.39733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Средняя цена в городе\nprice_in_city_dict = df.groupby('City')['Price_Range'].mean().to_dict()\ndf['Price_in_City'] = df['City'].map(price_in_city_dict)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:13:12.399992Z","iopub.execute_input":"2021-11-29T11:13:12.400554Z","iopub.status.idle":"2021-11-29T11:13:12.429063Z","shell.execute_reply.started":"2021-11-29T11:13:12.40033Z","shell.execute_reply":"2021-11-29T11:13:12.42802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Сокращаем список кухонь для анализа до N - основных, остальные Other\nN=30 #!!!\n\ns = df['Cuisine_Style'].apply(lambda x: get_cuisines(x))\nslist =[]\nfor x in s:\n    slist.extend(x)\ntopNcusines = set(pd.Series(slist).value_counts()[:N].index)  \ndf['Cuisine_top_N'] =df['Cuisine_Style'].apply(lambda x: is_cuisine_top_N(x))","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:13:12.430518Z","iopub.execute_input":"2021-11-29T11:13:12.430818Z","iopub.status.idle":"2021-11-29T11:13:13.341572Z","shell.execute_reply.started":"2021-11-29T11:13:12.430763Z","shell.execute_reply":"2021-11-29T11:13:13.340747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Сетевой ID ресторана (похоже, что это ID франшизы, если повторяется более 1-го раза - isNetworkRestorant)\nimport warnings; warnings.simplefilter('ignore')\ndf['Restaurant_net_id'] = df['Restaurant_id'].apply(lambda x: x.split('_')[1])\nNetworkRestorants = df[df['Restaurant_net_id'].isin(df['Restaurant_net_id'].value_counts()[df['Restaurant_net_id'].value_counts()>2].index)]\nNetworkRestorants['isNetworkRestorant'] = True\ndf['isNetworkRestorant'] = NetworkRestorants['isNetworkRestorant']\ndf['isNetworkRestorant'] = df['isNetworkRestorant'].fillna(False)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:13:13.342811Z","iopub.execute_input":"2021-11-29T11:13:13.343056Z","iopub.status.idle":"2021-11-29T11:13:13.474086Z","shell.execute_reply.started":"2021-11-29T11:13:13.343014Z","shell.execute_reply":"2021-11-29T11:13:13.473281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Помечаем, входит ли город в N-top городов, если ДА, то пишем его назавние, если НЕТ -Other\ntop_Cityes = df['City'].value_counts()[0:10].index.to_list()\n\ndf['TopCityes'] = df.City.apply(lambda x: x if x in top_Cityes else 'Other_City')","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:13:13.475657Z","iopub.execute_input":"2021-11-29T11:13:13.475975Z","iopub.status.idle":"2021-11-29T11:13:13.516125Z","shell.execute_reply.started":"2021-11-29T11:13:13.475918Z","shell.execute_reply":"2021-11-29T11:13:13.515333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.preprocessing import PolynomialFeature\n# does not improve MAE\n# pf = PolynomialFeatures(degree=2).fit_transform(df[['RankingScaled', 'Price_Range']])\n# poly_frame=pd.DataFrame(pf, columns=['c1','c2','c3','c4pr', 'c5pr', 'c6'])\n# df = pd.concat([df, poly_frame[['c4pr','c5pr']]], axis=1)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:13:13.517474Z","iopub.execute_input":"2021-11-29T11:13:13.517759Z","iopub.status.idle":"2021-11-29T11:13:13.521398Z","shell.execute_reply.started":"2021-11-29T11:13:13.517688Z","shell.execute_reply":"2021-11-29T11:13:13.520544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# does not improve MAE\n# pf = PolynomialFeatures(degree=2).fit_transform(df[['RankingScaled', 'isNetworkRestorant']])\n# poly_frame=pd.DataFrame(pf, columns=['c1','c2','c3','c4nr', 'c5nr', 'c6'])\n# df = pd.concat([df, poly_frame[['c4nr','c5nr']]], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:13:13.523089Z","iopub.execute_input":"2021-11-29T11:13:13.523763Z","iopub.status.idle":"2021-11-29T11:13:13.537707Z","shell.execute_reply.started":"2021-11-29T11:13:13.523691Z","shell.execute_reply":"2021-11-29T11:13:13.53695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df = df.drop(['c4pr', 'c5pr','c4nr', 'c5nr'], axis=1)\n# df.columns","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:13:13.539309Z","iopub.execute_input":"2021-11-29T11:13:13.539879Z","iopub.status.idle":"2021-11-29T11:13:13.549496Z","shell.execute_reply.started":"2021-11-29T11:13:13.539819Z","shell.execute_reply":"2021-11-29T11:13:13.548648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 8. Отсмотр признаков","metadata":{}},{"cell_type":"code","source":"lst = ['Ranking', 'Rating', 'Number_of_Reviews', 'City', 'Price_Range',\n        'Restaurant_id',  'Country',\n       'Restaurants_Count', 'Population', 'Restaurants_for_Population',\n       'Weighed_Rank',  'Cuisines_Count',\n       'RevTimeDelta', 'NewestReviewDate',\n       'TxtReviewsCount', 'Weighed_Rank_by_Population', 'PositiveWords','PositiveWords_in_Reviews',\n        'WRR', 'WRV', 'NRV', 'NRP', 'RankingScaled', 'Price_in_City', 'Restaurant_net_id', 'ReviewsSentiment', 'ReviewsWeekend']\ndf[lst].hist(figsize=(20, 20), bins=100);\nplt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:13:13.550966Z","iopub.execute_input":"2021-11-29T11:13:13.551516Z","iopub.status.idle":"2021-11-29T11:13:24.244424Z","shell.execute_reply.started":"2021-11-29T11:13:13.551456Z","shell.execute_reply":"2021-11-29T11:13:24.243308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"table_corr = abs(df.drop(['Train'],axis=1).corr().round(2))\nplt.rcParams['figure.figsize'] = (30,30)\nsns.heatmap(table_corr, vmin=0, vmax=1, cmap=\"cool\", linewidths=1,annot=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:13:24.245989Z","iopub.execute_input":"2021-11-29T11:13:24.246531Z","iopub.status.idle":"2021-11-29T11:13:31.173617Z","shell.execute_reply.started":"2021-11-29T11:13:24.246451Z","shell.execute_reply":"2021-11-29T11:13:31.172456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test(df)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:13:31.175567Z","iopub.execute_input":"2021-11-29T11:13:31.175935Z","iopub.status.idle":"2021-11-29T11:13:56.123647Z","shell.execute_reply.started":"2021-11-29T11:13:31.175873Z","shell.execute_reply":"2021-11-29T11:13:56.122609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Собираем dummies","metadata":{}},{"cell_type":"code","source":"# Собираем Dummies: city, price_range, country_range, Cuisine top N\n\ndff = pd.get_dummies(df['Cuisine_top_N'].apply(pd.Series).stack()).sum(level=0)\ndf_mcc = pd.get_dummies(df['Most_Common_Cusine_in_City'], prefix = 'MCC_')\ndf_city_dum = pd.get_dummies(df['City'], prefix = 'City_')\ndf_city_Top = pd.get_dummies(df['TopCityes'], prefix = 'City_Top', dummy_na=True)\ndf_price_range = pd.get_dummies(df['Price_Range'], prefix = 'Price_') \ndf_country_range = pd.get_dummies(df['Country'], prefix = 'Country_') \n# df_season_range = pd.get_dummies(df['NewestReviewSeason'], prefix = 'Season')\ndf_review_weekend = pd.get_dummies(df['ReviewsWeekend'], prefix = 'Weekend')\n\ndf['PositiveWordsList'] = df['PositiveWordsList'].fillna('PositiveWords_NAN')\ndf_positive_words_range = pd.get_dummies(df['PositiveWordsList'].apply(pd.Series).stack(), dummy_na=False).sum(level=0)\n\ndf1 = pd.concat([df,dff], axis=1)\ndf1 = pd.concat([df1,df_city_dum], axis=1)\ndf1 = pd.concat([df1,df_price_range], axis=1)\ndf1 = pd.concat([df1,df_country_range], axis=1)\ndf1 = pd.concat([df1,df_mcc], axis=1)\ndf1 = pd.concat([df1,df_positive_words_range], axis=1)\ndf1 = pd.concat([df1, df_review_weekend], axis=1)\n\n# df1 = pd.concat([df1,df_season_range], axis=1)\n\ncols_cuisine_style = dff.columns\ncols_city = df_city_dum.columns\ncols_price_range =  df_price_range.columns\ncols_country_range =  df_country_range.columns\ncols_mcc =  df_mcc.columns\ncols_positive_words = df_positive_words_range.columns\ncols_weekend = df_review_weekend.columns\n# cols_season = df_season_range.columns","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:13:56.125117Z","iopub.execute_input":"2021-11-29T11:13:56.12547Z","iopub.status.idle":"2021-11-29T11:14:26.080878Z","shell.execute_reply.started":"2021-11-29T11:13:56.125413Z","shell.execute_reply":"2021-11-29T11:14:26.080003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1.columns","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:14:26.082301Z","iopub.execute_input":"2021-11-29T11:14:26.08261Z","iopub.status.idle":"2021-11-29T11:14:26.088988Z","shell.execute_reply.started":"2021-11-29T11:14:26.082557Z","shell.execute_reply":"2021-11-29T11:14:26.088274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# table_corr = abs(df1[['Weekend_NA', 'Weekend_WEEKEND','Weekend_WORKDAY','ReviewsSentiment','Rating', 'NRP', 'NRV']].corr().round(2))\n# plt.rcParams['figure.figsize'] = (30,30)\n# sns.heatmap(table_corr, vmin=0, vmax=1, cmap=\"cool\", linewidths=1,annot=True)\n# df2  = df1.drop(['c4','c5'], axis=1)\n# 0.1597\ntest(df1)\n# df1.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:14:26.09021Z","iopub.execute_input":"2021-11-29T11:14:26.090705Z","iopub.status.idle":"2021-11-29T11:15:31.45765Z","shell.execute_reply.started":"2021-11-29T11:14:26.090641Z","shell.execute_reply":"2021-11-29T11:15:31.456676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"MAE с округлением: 0.15825 MAE без округления: 0.191565625\n\n\nMAE с округлением: 0.1583125 MAE без округления: 0.19127\n\nMAE с округлением: 0.1581875 MAE без округления: 0.19129125\n\n\nc5: MAE с округлением: 0.1598125 MAE без округления: 0.19272375\n\nc4+c5: MAE с округлением: 0.1584375 MAE без округления: 0.19307687499999998\n\nta_updated: MAE с округлением: 0.1420134373645427 MAE без округления: 0.17949013870827915\n\n\n\n\n","metadata":{}},{"cell_type":"code","source":"# Собираем признаки И Разбиваем датафрейм на части, необходимые для обучения и тестирования модели\ncolumns = [ 'isMultyCusine', 'Price_Range_NaN', 'Cuisine_Style_NAN', 'Number_of_Reviews_NAN', 'Number_of_Reviews',\n     'Restaurants_Count', 'Cuisines_Count', 'RevTimeDelta', 'NewestReviewDate', 'PositiveWords',  'Weighed_Rank',\n     'Ranking', 'Weighed_Rank_by_Population',  'Cusines_Count_In_City', 'WRR', 'ID_TA', 'Weighed_Rank_min_max',\n     'Price_in_City', 'isCapital', 'Population', 'Restaurants_for_Population' ]\ncolumns = ['Ranking', 'Price_Range', 'Number_of_Reviews', 'ID_TA', 'Train', 'Rating', 'Reviews_txt_NaN', 'Price_Range_NaN', \n           'Cuisine_Style_NAN', 'Cuisines_Count', 'Number_of_Reviews_NAN', 'RankingScaled', 'Country', 'Restaurants_Count', \n           'Population', 'Restaurants_for_Population', 'Visitors', 'Restaurants_for_Visitors', 'isCapital', 'Weighed_Rank', \n           'Weighed_Rank_min_max', 'isMostPopCusine', 'isMultyCusine', 'RevTimeDelta', 'NewestReviewDate', 'TxtReviewsCount', \n           'PositiveWords', 'ReviewsSentiment', 'Cusines_Count_In_City', 'Weighed_Cuisines_Count', 'Weighed_Rank_by_Population', \n           'Weighed_Rank_by_Visitors', 'PositiveWords_in_Reviews', 'Sentiments_in_Reviews', 'NRP', 'NRV', 'WRR', 'WRV', \n           'Relative_Price_Range', 'Price_in_City', 'isNetworkRestorant']\n\ncolumns.extend(cols_price_range.tolist())\ncolumns.extend(cols_cuisine_style.tolist())\ncolumns.extend(cols_city.tolist())\ncolumns.extend(cols_country_range.tolist())\ncolumns.extend(cols_positive_words.tolist())\ncolumns.extend(cols_weekend.tolist())\n\n#Разбиваем датафрейм на части, необходимые для обучения и тестирования модели\nX = df1[df1.Train][columns]\n\ny = df1[df1.Train]['Rating']","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:15:31.459047Z","iopub.execute_input":"2021-11-29T11:15:31.459383Z","iopub.status.idle":"2021-11-29T11:15:31.748355Z","shell.execute_reply.started":"2021-11-29T11:15:31.459335Z","shell.execute_reply":"2021-11-29T11:15:31.747586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 9. Class","metadata":{}},{"cell_type":"code","source":"class preprocessor():\n    def __init__(self, df_Train, df_Test, Sample_Submission):\n        '''Функция инициализации'''\n        self.df_train = df_Train\n        self.df_test = df_Test\n        self.sample_submission = Sample_Submission\n        self.pos_words_list = df_pos_words[0].to_list()\n        self.neg_words_list = df_neg_words[0].to_list()\n        self.allCusines = []\n        self.df_train['Train'] = True # помечаем где у нас трейн\n        self.df_test['Train'] = False # помечаем где у нас тест\n        self.df_test['Rating'] = 0 # в тесте у нас нет значения Rating, мы его должны предсказать, по этому пока просто заполняем нулями\n        self.data = df_test.append(df_train, sort=False).reset_index(drop=True) # объединяем\n        self.data.columns = list(map(lambda x: x.replace(\" \",\"_\"), data.columns))\n        self.df = data.drop('URL_TA',axis=1).copy()\n\n    \n    def get_df(self):\n        '''Получить новый датасет'''\n        return self.df\n\n    def clean_and_fill(self):\n        '''Очистить текущий датасет'''\n        self.df['ID_TA'] = self.df['ID_TA'].apply(lambda x: x[1:]).astype(int)\n\n        # Reviews - убираем NaN и \"причесываем\" текст отзывов \n        self.df['Reviews_txt_NaN'] = self.df['Reviews'].apply(lambda x: x ==  '[[], []]')\n        self.df['Reviews'] = self.df['Reviews'].fillna('[[], []]')\n        self.df['Reviews'] = self.df['Reviews'].apply(lambda x: cleanup_string(x))\n\n        # Number of Reviews\n        self.df['Number_of_Reviews_NAN'] = self.df['Number_of_Reviews'].isna()\n        replace_val = self.df['Number_of_Reviews'].mean()\n        replace_val = np.round(replace_val)\n        self.df['Number_of_Reviews'] = self.df['Number_of_Reviews'].fillna(replace_val)\n\n        # Перекодируем Price Range и удаляем NaN\n        cleanup_nums = {'Price_Range': {\"$\": 1, \"$$ - $$$\": 2, \"$$$$\": 3, np.NaN: 2}}\n        # чаще всего встречается \"$$ - $$$\", поэтому пропуски заменили на 2\n        self.df['Price_Range_NaN'] = self.df['Price_Range'].isna()\n        self.df.replace(cleanup_nums, inplace=True)\n\n        # Получаем Cuisines Count, самую популярную кухню, среднее к-во кухонь в ресторане и устраняем NaN\n        self.df['Cuisine_Style_NAN'] = self.df['Cuisine_Style'].isna()\n        self.df['Cuisine_Style'] = self.df['Cuisine_Style'].fillna('NaN')\n        self.df['Cuisines_Count'] = self.df.apply(cuisine_styles_count, axis=1)\n        self.most_popular_cusine = pd.Series(allCusines).value_counts().index[0]\n        self.average_cousines_count = np.round(df['Cuisines_Count'].mean())\n        \n        # выбросы Number of reviews\n        def scale_down(value):\n            if value > 2700:\n                value = value/100\n            return value\n        self.df.Number_of_Reviews = self.df.Number_of_Reviews.apply(scale_down)\n\n    def feature_engineering(self):\n        '''Добавить признаки в текущий датасет'''\n        population_city_dict = {}\n        country_city_dict = {}\n        \n        # Получаем словари популяции по городам, а так же ISO код страны по городу\n        population_city_dict, country_city_dict = get_city_population_and_country(self.df, df_city)\n\n        # Вычисляем страну для города в каждой строке\n        self.df['Country'] = self.df[\"City\"].apply(lambda x: country_city_dict[x])\n\n        # Вычисляем к-во ресторанов для города в каждой строке\n        restorants_in_city = self.df.groupby('City')['Ranking'].count().to_dict()\n        self.df['Restaurants_Count'] = self.df['City'].map(restorants_in_city)\n\n        # Вычисляем население (в тыс. чел) для города в каждой строке\n        self.df['Population'] = self.df[\"City\"].map(population_city_dict)\n\n        # Вычисляем к-во ресторанов на 1000 чел для города в каждой строке\n        self.df['Restaurants_for_Population'] = self.df.Restaurants_Count / (self.df['Population']*1000)\n        self.df['Visitors'] = self.df[\"City\"].map(VisitorsPerCity)\n        self.df['Restaurants_for_Visitors'] = (self.df.Restaurants_Count*1000) / df['Visitors']\n\n        # Вычисляем является ли город столицей в каждой строке\n        capital_city_dict = get_capital_city_dict(self.df, df_city)\n        self.df['isCapital'] = self.df[\"City\"].apply(lambda x: capital_city_dict[x])\n\n        # Получаем относительную позицию ресторана среди всех ресторанов города\n        self.df['Weighed_Rank'] = self.df.apply(lambda x: get_Weighed_Rank_RK(x), axis=1)\n\n        CityMinMax = self.df.groupby('City')['Ranking'].agg([min,max])\n        CityMinMax = CityMinMax.reset_index()\n        self.df['Weighed_Rank_min_max'] = self.df.apply(lambda x: get_Weighed_Rank(CityMinMax, x), axis=1)\n        \n        scalers = {}\n        self.df['RankingScaled']  = 0\n        cities = self.df.City.unique()\n        for city in cities:\n            c = self.df[self.df.City==city].Ranking\n            mi = c.min()\n            ma = c.max()\n            scalers[city]= [mi, ma]\n            c2 =  c.apply(lambda x: (x-mi)/(ma-mi)*1000)\n            self.df[self.df.City==city]['RankingScaled'] = c2\n            \n        def scale(row):\n            mi, ma = scalers[row.City]\n            row.RankingScaled = (row.Ranking-mi)/(ma-mi)*1000\n            return row\n        self.df = self.df.apply(scale, axis=1)\n\n        # Флаги (1/0) isMostPopCusine - есть ли в ресторане самая популярная кухня; isMultyCusine - к-во кухонь в ресторане больше или столько же чем в среднем\n        self.df['isMostPopCusine'] = self.df.Cuisine_Style.apply(lambda x: 1 if self.most_popular_cusine in x else 0 )\n        self.df['isMultyCusine'] = self.df.Cuisines_Count.apply(lambda x: 1 if  x >= self.average_cousines_count else 0 )\n\n        # RevTimeDelta - время между review в днях\n        self.df['RevTimeDelta'] = self.df.Reviews.apply(rev_time_delta)\n\n        # NewestReviewDate - время, прошедшее со момента последнего review\n        self.df['NewestReviewDate'] = self.df.Reviews.apply(lambda x: get_reviews(x)['reviews_dt'])\n        self.df['NewestReviewDate'] = self.df.NewestReviewDate.apply(lambda x: sorted(x,reverse=True)[0] if len(x)!=0 else pd.NaT)\n        self.df['NewestReviewDate'] = self.df.NewestReviewDate.fillna(dt.date(1970,1,1))\n        self.df['NewestReviewDate'] = self.df.NewestReviewDate.apply(lambda x: (CURRENT_DATE.date()-x).total_seconds()//86400)\n\n        self.df['NewestReviewSeason'] = self.df.Reviews.apply(lambda x: get_reviews(x)['reviews_dt'])\n        self.df['NewestReviewSeason'] = self.df.NewestReviewSeason.apply(lambda x: sorted(x,reverse=True)[0] if len(x)!=0 else pd.NaT)\n        self.df['ReviewsWeekend'] = self.df.NewestReviewSeason.apply(lambda x: is_weekend(x))\n        self.df['NewestReviewSeason'] = self.df.NewestReviewSeason.apply(lambda x: get_season(x))\n\n\n        #  'TxtReviewsCount' - к-во отзывов, не сильно улучшает результат, но пусть будут\n        self.df['TxtReviewsCount'] = self.df.Reviews.apply(lambda x: len(get_reviews(x)['reviews_txt']))\n\n        self.df['ReviewsSentiment'] = self.df['Reviews'].apply(review_sentiment)\n        mean = self.df.ReviewsSentiment.median()\n        self.df['ReviewsSentiment'] = self.df['ReviewsSentiment'].apply(lambda x: mean if x==0 else x)\n        self.df['Sentiments_in_Reviews'] = self.df['ReviewsSentiment'] / self.df['Number_of_Reviews']\n        \n        # К-во позитивных слов в представленных отзывах\n        self.df['PositiveWords'] = self.df.Reviews.apply(lambda x: count_positive_words_proportion(x))\n        # Список уникальных позитивных слов в представленных отзывах\n        self.df['PositiveWordsList'] = self.df.Reviews.apply(lambda x: list_positive_words(x))\n        self.df['PositiveWordsList'] = self.df['PositiveWordsList'].fillna('PositiveWords_NAN')\n        self.df['PositiveWords_in_Reviews'] = self.df['PositiveWords'] / self.df['Number_of_Reviews']\n\n\n        # К-во негативных слов в представленных отзывах\n        self.df['NegativeWords'] = self.df.Reviews.apply(lambda x: count_negative_words_proportion(x))\n        # Список уникальных негативных слов в представленных отзывах\n        self.df['NegativeWordsList'] = self.df.Reviews.apply(lambda x: list_negative_words(x))\n        self.df['NegativeWordsList'] = self.df['NegativeWordsList'].fillna('NegativeWords_NAN')\n        self.df['NegativeWords_in_Reviews'] = self.df['NegativeWords'] / self.df['Number_of_Reviews']\n\n        cusines_in_city={}\n        cusines_count_in_city={}\n        for city_name, group in self.df.groupby('City'):\n            #Получим серию со списками кухонь для групп\n            cusines = group['Cuisine_Style'].apply(get_cuisines)\n            #Получим список кухонь в группе\n            cusines_list = list(itertools.chain.from_iterable(cusines))\n            #Посчитаем и запишем число совпадений для каждой кухни в каждой группе при помощи Counter\n            cusines_in_city[city_name] = Counter(cusines_list)    \n        for city_name in cusines_in_city.keys():\n            cusines_count_in_city[city_name] = len(cusines_in_city[city_name])\n        self.df['Cusines_Count_In_City'] = self.df.City.map(cusines_count_in_city)\n\n        # Относительная доля кухонь в ресторане\n        self.df['Weighed_Cuisines_Count'] = self.df['Cuisines_Count'] / self.df['Cusines_Count_In_City']  \n        # Самая популярная кухня в городе\n        self.df['Most_Common_Cusine_in_City'] = self.df['City'].apply(lambda x: cusines_in_city[x].most_common(1)[0][0])\n        # Заменим пропуски на самую популярную\n        self.df['Cuisine_Style'] = self.df.apply(lambda x: x['Cuisine_Style'] if x['Cuisine_Style_NAN'] ==False else [x['Most_Common_Cusine_in_City']], axis=1)\n\n        # зависимость места ресторана в городе от населения\n        self.df['Weighed_Rank_by_Population'] = self.df['Weighed_Rank']  / self.df['Population']\n        self.df['Weighed_Rank_by_Visitors'] = self.df['Weighed_Rank']  / self.df['Visitors'] \n\n\n        # Как часто в городе оставляют отзывы\n        self.df['NRP'] = self.df['Number_of_Reviews'] / self.df['Population']\n        self.df['NRV'] = self.df['Number_of_Reviews'] / self.df['Visitors']\n        # Ранг ресторана с учетом частоты отзывов в городе\n        self.df['WRR'] =  self.df['Weighed_Rank']  *  self.df['NRP'] \n        self.df['WRV'] =  self.df['Weighed_Rank']  *  self.df['NRV'] \n\n        self.df['Relative_Price_Range'] = self.df['Price_Range'] / self.df['Weighed_Rank']\n\n        # Средняя цена в городе\n        price_in_city_dict = self.df.groupby('City')['Price_Range'].mean().to_dict()\n        self.df['Price_in_City'] = self.df['City'].map(price_in_city_dict)\n\n        # Сокращаем список кухонь для анализа до N - основных, остальные Other\n        N=30 #!!!\n\n        s = self.df['Cuisine_Style'].apply(lambda x: get_cuisines(x))\n        slist =[]\n        for x in s:\n            slist.extend(x)\n        self.topNcusines = set(pd.Series(slist).value_counts()[:N].index)  \n        self.df['Cuisine_top_N'] =self.df['Cuisine_Style'].apply(lambda x: is_cuisine_top_N(x))\n\n\n\n        # Сетевой ID ресторана (похоже, что это ID франшизы, если повторяется более 1-го раза - isNetworkRestorant)\n        import warnings; warnings.simplefilter('ignore')\n        self.df['Restaurant_net_id'] = self.df['Restaurant_id'].apply(lambda x: x.split('_')[1])\n        NetworkRestorants = self.df[self.df['Restaurant_net_id'].isin(self.df['Restaurant_net_id'].value_counts()[self.df['Restaurant_net_id'].value_counts()>2].index)]\n        NetworkRestorants['isNetworkRestorant'] = True\n        self.df['isNetworkRestorant'] = NetworkRestorants['isNetworkRestorant']\n        self.df['isNetworkRestorant'] = self.df['isNetworkRestorant'].fillna(False)\n\n        # Помечаем, входит ли город в N-top городов, если ДА, то пишем его назавние, если НЕТ -Other\n        top_Cityes = self.df['City'].value_counts()[0:10].index.to_list()\n        self.df['TopCityes'] = self.df.City.apply(lambda x: x if x in top_Cityes else 'Other_City')\n    \n    def dummies(self):\n        '''Добавить dummies в текущий датасет'''\n\n        df_Cuisine_top_N = pd.get_dummies(self.df['Cuisine_top_N'].apply(pd.Series).stack()).sum(level=0)\n        df_mcc = pd.get_dummies(self.df['Most_Common_Cusine_in_City'], prefix = 'MCC')\n        df_city_dum = pd.get_dummies(self.df['City'], prefix = 'City')\n        df_price = pd.get_dummies(self.df['Price_Range'], prefix = 'Price') \n        df_country = pd.get_dummies(self.df['Country'], prefix = 'Country') \n        # df_season = pd.get_dummies(df['NewestReviewSeason'], prefix = 'Season')\n        df_review_weekend = pd.get_dummies(df['ReviewsWeekend'], prefix = 'Weekend')\n        df_positive_words = pd.get_dummies(self.df['PositiveWordsList'].apply(pd.Series).stack(), dummy_na=False).sum(level=0)\n        df_negative_words = pd.get_dummies(self.df['NegativeWordsList'].apply(pd.Series).stack(), dummy_na=False).sum(level=0)\n\n\n        #object_columns = []\n        #for s in (self.df.columns):\n        #    if self.df[s].dtypes == 'object':\n        #        object_columns.append(s)\n        #        print(s, self.df[s].dtypes)\n        #object_columns = [s for s in self.df.columns if (self.df[s].dtypes == 'object')]\n\n        self.df = pd.concat([self.df, df_Cuisine_top_N], axis=1)\n        self.df = pd.concat([self.df, df_city_dum], axis=1)\n        self.df = pd.concat([self.df, df_price], axis=1)\n        self.df = pd.concat([self.df, df_country], axis=1)\n        self.df = pd.concat([self.df, df_mcc], axis=1)\n        self.df = pd.concat([self.df, df_positive_words], axis=1)\n        self.df = pd.concat([self.df, df_negative_words], axis=1)\n        # self.df = pd.concat([self.df, df_season], axis=1)\n        self.df = pd.concat([self.df, df_review_weekend], axis=1)\n\n        self.cols_cuisine_style = df_Cuisine_top_N.columns\n        self.cols_city = df_city_dum.columns\n        self.cols_price =  df_price.columns\n        self.cols_country =  df_country.columns\n        self.cols_mcc =  df_mcc.columns\n        self.cols_positive_words = df_positive_words.columns\n        self.cols_negative_words = df_negative_words.columns\n        # self.cols_season = df_season.columns\n        self.cols_review_weekend = df_review_weekend.columns\n      \n        #object_columns = self.df.dtypes[self.df.dtypes == 'object'].keys()\n        #self.df.drop(object_columns, axis = 1, inplace=True)\n\n        # Собираем признаки И Разбиваем датафрейм на части, необходимые для обучения и тестирования модели\n        self.columns = [ 'isMultyCusine', 'Price_Range_NaN', 'Cuisine_Style_NAN', 'Number_of_Reviews_NAN', 'Number_of_Reviews',\n             'Restaurants_Count', 'Cuisines_Count', 'RevTimeDelta', 'NewestReviewDate', 'PositiveWords',  'Weighed_Rank',\n             'Ranking', 'Weighed_Rank_by_Population',  'Cusines_Count_In_City', 'WRR', 'ID_TA', 'Weighed_Rank_min_max',\n             'Price_in_City', 'isCapital', 'Population', 'Restaurants_for_Population', \n             'Reviews_txt_NaN','isMostPopCusine', 'TxtReviewsCount', 'NegativeWords', 'NegativeWords_in_Reviews', 'PositiveWords_in_Reviews',\n             'Weighed_Cuisines_Count', 'Relative_Price_Range',  'isNetworkRestorant' ]\n        \n        self.columns = ['Ranking', 'Number_of_Reviews', 'ID_TA', 'Reviews_txt_NaN', \n                        'Price_Range_NaN', 'Cuisine_Style_NAN', 'Cuisines_Count', 'Number_of_Reviews_NAN', 'RankingScaled', \n                        'Restaurants_Count', 'Population', 'Restaurants_for_Population', 'Visitors', \n                        'Restaurants_for_Visitors', 'isCapital', 'Weighed_Rank', 'Weighed_Rank_min_max', \n                        'isMostPopCusine', 'isMultyCusine', 'RevTimeDelta', 'NewestReviewDate', 'TxtReviewsCount', 'PositiveWords', \n                        'ReviewsSentiment', 'Cusines_Count_In_City', 'Weighed_Cuisines_Count', 'Weighed_Rank_by_Population', \n                        'Weighed_Rank_by_Visitors', 'PositiveWords_in_Reviews', 'Sentiments_in_Reviews', 'NRP', 'NRV', 'WRR', 'WRV', \n                        'Relative_Price_Range', 'Price_in_City', 'isNetworkRestorant']\n        \n        self.columns.extend(self.cols_price.tolist())\n        self.columns.extend(self.cols_cuisine_style.tolist())\n        self.columns.extend(self.cols_city.tolist())\n        self.columns.extend(self.cols_country.tolist())\n        self.columns.extend(self.cols_mcc.tolist())\n        self.columns.extend(self.cols_positive_words.tolist())\n        self.columns.extend(self.cols_negative_words.tolist())\n        self.columns.extend(self.cols_review_weekend.tolist())\n\n    def Run(self):\n        '''Выполнить все действия'''\n        self.clean_and_fill()\n        self.feature_engineering()\n        self.dummies()\n    \n    def get_X_y(self):\n        '''Разбиваем датафрейм на части, необходимые для обучения и тестирования модели'''\n        X = self.df[self.df.Train][self.columns]\n        y = self.df[self.df.Train]['Rating']\n        return (X,y)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:15:31.750399Z","iopub.execute_input":"2021-11-29T11:15:31.750939Z","iopub.status.idle":"2021-11-29T11:15:31.855149Z","shell.execute_reply.started":"2021-11-29T11:15:31.750703Z","shell.execute_reply":"2021-11-29T11:15:31.854319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prepro = preprocessor(df_train, df_test, sample_submission)\nprepro.Run()\ndf1 = prepro.df\ndf1.columns\n","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:24:25.643997Z","iopub.execute_input":"2021-11-29T11:24:25.64438Z","iopub.status.idle":"2021-11-29T11:28:23.212366Z","shell.execute_reply.started":"2021-11-29T11:24:25.644315Z","shell.execute_reply":"2021-11-29T11:28:23.21116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X, y = prepro.get_X_y()\ncolumns = prepro.columns","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:28:31.620567Z","iopub.execute_input":"2021-11-29T11:28:31.620897Z","iopub.status.idle":"2021-11-29T11:28:32.342603Z","shell.execute_reply.started":"2021-11-29T11:28:31.62084Z","shell.execute_reply":"2021-11-29T11:28:32.341669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_cols = set(X.columns)\nf_cols = set(df1.columns)\nf_cols - x_cols","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:28:32.743837Z","iopub.execute_input":"2021-11-29T11:28:32.744298Z","iopub.status.idle":"2021-11-29T11:28:32.751573Z","shell.execute_reply.started":"2021-11-29T11:28:32.744253Z","shell.execute_reply":"2021-11-29T11:28:32.750854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 10. Model ","metadata":{}},{"cell_type":"code","source":"# Наборы данных с меткой \"train\" будут использоваться для обучения модели, \"test\" - для тестирования.\n# Для тестирования мы будем использовать 20% от исходного датасета.\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)\n\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)\n\n# Создаём модель (НАСТРОЙКИ НЕ ТРОГАЕМ)\nregr = RandomForestRegressor(n_estimators=100, verbose=1, n_jobs=-1, random_state=RANDOM_SEED)\n\n# Обучаем модель на тестовом наборе данных\nregr.fit(X_train, y_train)\n\n# Используем обученную модель для предсказания рейтинга ресторанов в тестовой выборке.\n# Предсказанные значения записываем в переменную y_pred\ny_pred = regr.predict(X_test)\ny_pred_old = y_pred.copy()\ny_pred = round_of_rating(y_pred) \n\n# Сравниваем предсказанные значения (y_pred) с реальными (y_test), и смотрим насколько они в среднем отличаются\n# Метрика называется Mean Absolute Error (MAE) и показывает среднее отклонение предсказанных значений от фактических.\nprint('MAE с округлением:', metrics.mean_absolute_error(y_test, y_pred), 'MAE без округления:', metrics.mean_absolute_error(y_test, y_pred_old) )","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:29:18.515424Z","iopub.execute_input":"2021-11-29T11:29:18.516064Z","iopub.status.idle":"2021-11-29T11:30:46.992016Z","shell.execute_reply.started":"2021-11-29T11:29:18.516013Z","shell.execute_reply":"2021-11-29T11:30:46.990701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (10,10)\nfeat_importances = pd.Series(regr.feature_importances_, index=X.columns)\nfeat_importances.nlargest(30).plot(kind='barh')","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:31:01.166634Z","iopub.execute_input":"2021-11-29T11:31:01.167048Z","iopub.status.idle":"2021-11-29T11:31:01.747035Z","shell.execute_reply.started":"2021-11-29T11:31:01.167008Z","shell.execute_reply":"2021-11-29T11:31:01.746108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 11. Submission","metadata":{}},{"cell_type":"code","source":"# Предсказываем рейтинги на датасете для предсказаний (Train == False)\nX_submission = df1[df1.Train == False][columns]\ny_pred_submission = round_of_rating(regr.predict(X_submission))","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:31:08.552454Z","iopub.execute_input":"2021-11-29T11:31:08.552755Z","iopub.status.idle":"2021-11-29T11:31:10.835134Z","shell.execute_reply.started":"2021-11-29T11:31:08.552708Z","shell.execute_reply":"2021-11-29T11:31:10.834297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Формируем датасет с предсказаниями Restaurant_id -- Rating\nsubmission_df = pd.DataFrame()\nsubmission_df['Restaurant_id'] = df1[df1.Train == False]['Restaurant_id']\nsubmission_df['Rating'] = y_pred_submission\nsubmission_df.head(15)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:31:25.854264Z","iopub.execute_input":"2021-11-29T11:31:25.854931Z","iopub.status.idle":"2021-11-29T11:31:25.928358Z","shell.execute_reply.started":"2021-11-29T11:31:25.854879Z","shell.execute_reply":"2021-11-29T11:31:25.927673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Тренировочный датасет')\ndf[df.Train].Rating.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:32:03.73855Z","iopub.execute_input":"2021-11-29T11:32:03.739007Z","iopub.status.idle":"2021-11-29T11:32:03.760932Z","shell.execute_reply.started":"2021-11-29T11:32:03.738963Z","shell.execute_reply":"2021-11-29T11:32:03.760019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Предсказания масштабированные в 4 раза')\nsubmission_df.Rating.value_counts()*4","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:32:04.424839Z","iopub.execute_input":"2021-11-29T11:32:04.425159Z","iopub.status.idle":"2021-11-29T11:32:04.436727Z","shell.execute_reply.started":"2021-11-29T11:32:04.42511Z","shell.execute_reply":"2021-11-29T11:32:04.43575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"h = df[df.Train].Rating.hist()\nf = submission_df.Rating.hist()\nfig = h.get_figure()\nfig = f.get_figure()","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:32:06.244496Z","iopub.execute_input":"2021-11-29T11:32:06.244993Z","iopub.status.idle":"2021-11-29T11:32:06.621786Z","shell.execute_reply.started":"2021-11-29T11:32:06.244929Z","shell.execute_reply":"2021-11-29T11:32:06.620719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Распределения достаточно похожи - ОК!\n# Сохраняем предсказания\nsubmission_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:32:08.423144Z","iopub.execute_input":"2021-11-29T11:32:08.42377Z","iopub.status.idle":"2021-11-29T11:32:08.45952Z","shell.execute_reply.started":"2021-11-29T11:32:08.423721Z","shell.execute_reply":"2021-11-29T11:32:08.458843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:32:09.959154Z","iopub.execute_input":"2021-11-29T11:32:09.959645Z","iopub.status.idle":"2021-11-29T11:32:09.987032Z","shell.execute_reply.started":"2021-11-29T11:32:09.959604Z","shell.execute_reply":"2021-11-29T11:32:09.986332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df","metadata":{"execution":{"iopub.status.busy":"2021-11-29T11:32:18.133788Z","iopub.execute_input":"2021-11-29T11:32:18.134098Z","iopub.status.idle":"2021-11-29T11:32:18.147426Z","shell.execute_reply.started":"2021-11-29T11:32:18.13405Z","shell.execute_reply":"2021-11-29T11:32:18.146623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}